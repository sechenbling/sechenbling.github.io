

<feed xmlns="http://www.w3.org/2005/Atom">
  <id>http://localhost:4000/</id>
  <title>Blingblogs</title>
  <subtitle>A site with blogs involve backend, big data, or other daily programming records.</subtitle>
  <updated>2024-02-06T00:02:46+08:00</updated>
  <author>
    <name>Lynn Chen</name>
    <uri>http://localhost:4000/</uri>
  </author>
  <link rel="self" type="application/atom+xml" href="http://localhost:4000/feed.xml"/>
  <link rel="alternate" type="text/html" hreflang="en"
    href="http://localhost:4000/"/>
  <generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator>
  <rights> © 2024 Lynn Chen </rights>
  <icon>/assets/img/favicons/favicon.ico</icon>
  <logo>/assets/img/favicons/favicon-96x96.png</logo>


  
  <entry>
    <title>HDFS ShellCmd&amp;API</title>
    <link href="http://localhost:4000/posts/HDFS-ShellCmd&amp;API/" rel="alternate" type="text/html" title="HDFS ShellCmd&amp;API" />
    <published>2024-02-01T22:35:00+08:00</published>
  
    <updated>2024-02-01T22:35:00+08:00</updated>
  
    <id>http://localhost:4000/posts/HDFS-ShellCmd&amp;API/</id>
    <content src="http://localhost:4000/posts/HDFS-ShellCmd&amp;API/" />
    <author>
      <name>Lynn</name>
    </author>

  
    
    <category term="Bigdata" />
    
    <category term="Hadoop" />
    
  

  
    <summary>
      





      HDFS 命令

hadoop fs -xxx和hdfs dfs -xxx 最终效果和命令都是一样的 两个都可以使用

hadoop fs -moveFromLocal /local /remote	从本地剪切粘贴到 HDFS
hadoop fs -copyFromLocal /local /remote 	从本地文件系统中拷贝文件到 HDFS 路径去
hadoop fs -put /local /remote	-put：等同于 -copyFromLocal
hadoop fs -appendToFile /local /remote	追加一个文件到已经存在的文件末尾
hadoop fs -copyToLocal /remote	从 HDFS 拷贝到本地
hadoop fs -get /remote	等同于 copyToLocal
hadoop fs -ls /remote	显示目录...
    </summary>
  

  </entry>

  
  <entry>
    <title>HDFS DataNode</title>
    <link href="http://localhost:4000/posts/HDFS-DataNode/" rel="alternate" type="text/html" title="HDFS DataNode" />
    <published>2024-02-01T22:34:00+08:00</published>
  
    <updated>2024-02-01T22:34:00+08:00</updated>
  
    <id>http://localhost:4000/posts/HDFS-DataNode/</id>
    <content src="http://localhost:4000/posts/HDFS-DataNode/" />
    <author>
      <name>Lynn</name>
    </author>

  
    
    <category term="Bigdata" />
    
    <category term="Hadoop" />
    
  

  
    <summary>
      





      DataNode




    </summary>
  

  </entry>

  
  <entry>
    <title>Read&amp;Write Process</title>
    <link href="http://localhost:4000/posts/HDFS-Read&amp;Write-Process/" rel="alternate" type="text/html" title="Read&amp;Write Process" />
    <published>2024-02-01T22:33:00+08:00</published>
  
    <updated>2024-02-01T22:33:00+08:00</updated>
  
    <id>http://localhost:4000/posts/HDFS-Read&amp;Write-Process/</id>
    <content src="http://localhost:4000/posts/HDFS-Read&amp;Write-Process/" />
    <author>
      <name>Lynn</name>
    </author>

  
    
    <category term="Bigdata" />
    
    <category term="Hadoop" />
    
  

  
    <summary>
      





      写入数据的流程：

  客户端创建分布式文件系统DistributedFileSystem
  向NameNode请求上传文件
    
      NameNode检查权限
      NameNode检查目录结构（目录是否存在）
    
  
  NameNode响应可以上传文件
  客户端请求上传第一个Block(0-128M)，请求NameNode返回DataNode
  NameNode返回多个DataNode表示这三个节点存储数据
    
      选择策略(节点距离最近，负载均衡)：
        
          本地节点
          其他机架的一个节点
          其他机架的另一个节点
        
      
    
  
  客户端创建FSDataOutputStream上传数据，向一个DN请求建立Block传输通道，之后再由...
    </summary>
  

  </entry>

  
  <entry>
    <title>HDFS NameNode&amp;SecondaryNameNode</title>
    <link href="http://localhost:4000/posts/HDFS-NameNode&amp;SecondaryNameNode/" rel="alternate" type="text/html" title="HDFS NameNode&amp;SecondaryNameNode" />
    <published>2024-02-01T22:33:00+08:00</published>
  
    <updated>2024-02-01T22:33:00+08:00</updated>
  
    <id>http://localhost:4000/posts/HDFS-NameNode&amp;SecondaryNameNode/</id>
    <content src="http://localhost:4000/posts/HDFS-NameNode&amp;SecondaryNameNode/" />
    <author>
      <name>Lynn</name>
    </author>

  
    
    <category term="Bigdata" />
    
    <category term="Hadoop" />
    
  

  
    <summary>
      





      
  
    fslmage 镜像文件：存储数据
HDFS文件系统元数据的一个永久性的检查点，其中包含HDFS文件系统的所有目录和文件inode的序列化信息。
  
  
    Edits 记录变化的步骤
存放HDFS文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到Edits文件当中
    
      seen_txid:记录当前最新的Edits(即最后一个Edits的数字
      VERSION：记录集群ID
    
  


每次NameNode启动的时候都会将Fsimage文件读入内存，加载Edits的更新操作，保证数据是最新的同步的，可以看作NameNode启动的时候就将Fsimage和Edits文件进行了合并


  上线后内存的中出现的是fslmage和执行完Edits后的结果

    
      差别在inprogress这个...
    </summary>
  

  </entry>

  
  <entry>
    <title>Hadoop HDFS Structure</title>
    <link href="http://localhost:4000/posts/HDFS-Structure/" rel="alternate" type="text/html" title="Hadoop HDFS Structure" />
    <published>2024-02-01T22:31:00+08:00</published>
  
    <updated>2024-02-01T22:31:00+08:00</updated>
  
    <id>http://localhost:4000/posts/HDFS-Structure/</id>
    <content src="http://localhost:4000/posts/HDFS-Structure/" />
    <author>
      <name>Lynn</name>
    </author>

  
    
    <category term="Bigdata" />
    
    <category term="Hadoop" />
    
  

  
    <summary>
      





      NameNode：master 主管管理者

  管理HDFS的名称空间（原数据）
  配置副本策略
    
      设置不同数据的副本的数量
    
  
  管理数据块的映射信息
    
      比较大的文件分块存储，而且块和块之间的存储没有关系
    
  
  处理客户端的读写请求


DataNode
就是slave worker，NameNode下达命令由DataNode执行实际的操作

  存储实际的数据块
  执行数据块的读写操作




SecondaryNameNode 2NN

  并非NameNode的热备，当NN挂掉的时候它并不能马上替换NN提供服务
  辅助NN分担工作：比如定期合并镜像文件和编辑日志(Fsimage&amp;amp;Edits)并推送给NN
  紧急情况下可以恢复部分数据（不是所有数据都给了2NN）


Client 客户端

 ...
    </summary>
  

  </entry>

</feed>


